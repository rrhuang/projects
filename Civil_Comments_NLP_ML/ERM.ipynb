{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdhzt4qPmHxo",
        "outputId": "d1a94ae2-7f45-4350-d4af-ab95d1891028"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wilds\n",
            "  Downloading wilds-2.0.0-py3-none-any.whl (126 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.2/126.2 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.19.1 in /usr/local/lib/python3.10/dist-packages (from wilds) (1.22.4)\n",
            "Collecting ogb>=1.2.6 (from wilds)\n",
            "  Downloading ogb-1.3.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting outdated>=0.2.0 (from wilds)\n",
            "  Downloading outdated-0.2.2-py2.py3-none-any.whl (7.5 kB)\n",
            "Requirement already satisfied: pandas>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from wilds) (1.5.3)\n",
            "Requirement already satisfied: pillow>=7.2.0 in /usr/local/lib/python3.10/dist-packages (from wilds) (8.4.0)\n",
            "Requirement already satisfied: pytz>=2020.4 in /usr/local/lib/python3.10/dist-packages (from wilds) (2022.7.1)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from wilds) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision>=0.8.2 in /usr/local/lib/python3.10/dist-packages (from wilds) (0.15.2+cu118)\n",
            "Requirement already satisfied: tqdm>=4.53.0 in /usr/local/lib/python3.10/dist-packages (from wilds) (4.65.0)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from wilds) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.5.4 in /usr/local/lib/python3.10/dist-packages (from wilds) (1.10.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.2.6->wilds) (1.16.0)\n",
            "Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.2.6->wilds) (1.26.15)\n",
            "Requirement already satisfied: setuptools>=44 in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->wilds) (67.7.2)\n",
            "Collecting littleutils (from outdated>=0.2.0->wilds)\n",
            "  Downloading littleutils-0.2.2.tar.gz (6.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->wilds) (2.27.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.0->wilds) (2.8.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->wilds) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->wilds) (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->wilds) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->wilds) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->wilds) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->wilds) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->wilds) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->wilds) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7.0->wilds) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7.0->wilds) (16.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7.0->wilds) (2.1.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->wilds) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->wilds) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->wilds) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7.0->wilds) (1.3.0)\n",
            "Building wheels for collected packages: littleutils\n",
            "  Building wheel for littleutils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for littleutils: filename=littleutils-0.2.2-py3-none-any.whl size=7029 sha256=e707c2723c5e65a385874684678d5dd0156e2b9e85f85320b7b5fadfdfddf973\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/fe/b0/27a9892da57472e538c7452a721a9cf463cc03cf7379889266\n",
            "Successfully built littleutils\n",
            "Installing collected packages: littleutils, outdated, ogb, wilds\n",
            "Successfully installed littleutils-0.2.2 ogb-1.3.6 outdated-0.2.2 wilds-2.0.0\n"
          ]
        }
      ],
      "source": [
        "pip install wilds"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "!pip uninstall torch-scatter torch-sparse torch-geometric torch-cluster  --y\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
        "!pip install torch-cluster -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
        "!pip install git+https://github.com/pyg-team/pytorch_geometric.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRQWCB76f4m1",
        "outputId": "803c97f4-f5bb-4904-80d9-e0d69bb17df9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping torch-scatter as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torch-sparse as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torch-geometric as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torch-cluster as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.0.1+cu118.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu118/torch_scatter-2.1.1%2Bpt20cu118-cp310-cp310-linux_x86_64.whl (10.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m99.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.1.1+pt20cu118\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.0.1+cu118.html\n",
            "Collecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu118/torch_sparse-0.6.17%2Bpt20cu118-cp310-cp310-linux_x86_64.whl (4.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-sparse) (1.10.1)\n",
            "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-sparse) (1.22.4)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.17+pt20cu118\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.0.1+cu118.html\n",
            "Collecting torch-cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu118/torch_cluster-1.6.1%2Bpt20cu118-cp310-cp310-linux_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m76.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-cluster) (1.10.1)\n",
            "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-cluster) (1.22.4)\n",
            "Installing collected packages: torch-cluster\n",
            "Successfully installed torch-cluster-1.6.1+pt20cu118\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/pyg-team/pytorch_geometric.git\n",
            "  Cloning https://github.com/pyg-team/pytorch_geometric.git to /tmp/pip-req-build-s5dqgjvf\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/pyg-team/pytorch_geometric.git /tmp/pip-req-build-s5dqgjvf\n",
            "  Resolved https://github.com/pyg-team/pytorch_geometric.git to commit 38da3c68f0be67feb6cc77584ee68bcd32059739\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.4.0) (4.65.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.4.0) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.4.0) (1.10.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.4.0) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.4.0) (2.27.1)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.4.0) (3.0.9)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.4.0) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.4.0) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric==2.4.0) (2.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric==2.4.0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric==2.4.0) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric==2.4.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric==2.4.0) (3.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric==2.4.0) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric==2.4.0) (3.1.0)\n",
            "Building wheels for collected packages: torch_geometric\n",
            "  Building wheel for torch_geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch_geometric: filename=torch_geometric-2.4.0-py3-none-any.whl size=937978 sha256=646abd102a6ad9c6134ddedd6f83d9463fc15596103d88801789b004c2ccae53\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-d9h7twij/wheels/d3/78/eb/9e26525b948d19533f1688fb6c209cec8a0ba793d39b49ae8f\n",
            "Successfully built torch_geometric\n",
            "Installing collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.vocab import GloVe\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torchtext.data import get_tokenizer\n",
        "from torchtext.vocab import GloVe\n",
        "import re\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from wilds import get_dataset\n",
        "from wilds.common.data_loaders import get_train_loader\n",
        "import torchvision.transforms as transforms\n",
        "from wilds.common.grouper import CombinatorialGrouper\n",
        "from wilds.common.utils import split_into_groups\n",
        "from torch.autograd import grad\n",
        "\n",
        "class ToxicClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, embeddings_vectors, hidden_dim = 32, output_dim = 1):\n",
        "        super(ToxicClassifier, self).__init__()\n",
        "        self.embedding = nn.Embedding.from_pretrained(embeddings_vectors, freeze=True)\n",
        "        self.rnn = nn.GRU(embedding_dim, hidden_dim, batch_first=True)\n",
        "        self.output = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, text):\n",
        "        embedded = self.embedding(text)\n",
        "        _, embedded = self.rnn(embedded)\n",
        "        return self.output(embedded[-1])\n",
        "\n",
        "def tokenize(text, max_length = 100):\n",
        "    tokenizer = get_tokenizer('basic_english')\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"([.!?,'*])\", r\"\", text)\n",
        "    text = re.sub(r\"([-])\", r\" \", text)\n",
        "    tokens = tokenizer(text)\n",
        "    if len(tokens) < max_length:\n",
        "      tokens.extend(['<PAD>']*(max_length - len(tokens)))\n",
        "    tokens = tokens[:max_length]\n",
        "    tokens = [glove.stoi.get(token, len(glove.stoi) - 1) for token in tokens]\n",
        "    tokens = np.array(tokens, dtype=np.int64)\n",
        "    return tokens\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "glove = GloVe(name='6B', dim=token_dim)\n",
        "padding_vector = torch.zeros(token_dim)\n",
        "padding_token = '<PAD>'\n",
        "glove.itos.append(padding_token)  \n",
        "glove.stoi[padding_token] = len(glove.itos) - 1 \n",
        "glove.vectors = torch.cat((glove.vectors, padding_vector.unsqueeze(0)), dim=0) \n",
        "batch_size = 32\n",
        "token_dim = 50\n",
        "length = 100\n",
        "\n",
        "dataset = get_dataset(dataset=\"civilcomments\", download=True)\n",
        "train_data = dataset.get_subset(\n",
        "    \"train\")\n",
        "train_loader = get_train_loader(\"standard\", train_data, batch_size=32)\n",
        "test_data = dataset.get_subset(\n",
        "    \"val\")\n",
        "test_loader = get_train_loader(\"standard\", train_data, batch_size=32)\n",
        "\n",
        "from wilds.common.grouper import CombinatorialGrouper\n",
        "unawareness = CombinatorialGrouper(dataset, ['identity_any'])\n",
        "\n",
        "train_loader = get_train_loader(\n",
        "    \"group\", train_data, grouper=unawareness, n_groups_per_batch=1, batch_size=32\n",
        ")\n",
        "\n",
        "negative_samples = (train_data.y_array == 0).sum()\n",
        "positive_samples = (train_data.y_array == 1).sum()\n",
        "pos_weight = negative_samples / positive_samples\n",
        "\n",
        "model = ToxicClassifier(len(glove), token_dim, glove.vectors.to(device))\n",
        "model = model.to(device)\n",
        "criterion = nn.BCEWithLogitsLoss(pos_weight = pos_weight)\n",
        "optimizer = optim.Adam(model.parameters(), lr = 1e-1)\n",
        "scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.1, patience = 10)\n",
        "num_epochs = 20\n",
        "for epoch in range(0, num_epochs):\n",
        "  train_loss = 0.0\n",
        "  train_correct = 0\n",
        "  train_total = 0\n",
        "  model.train()\n",
        "  pbar = tqdm(train_loader)\n",
        "  for _ , cur_train in enumerate(pbar):\n",
        "      input, label, metadata = cur_train\n",
        "      if metadata[:,8].sum() == 0:\n",
        "        input = tuple(map(tokenize, input))\n",
        "        input = torch.Tensor(input).long().to(device)\n",
        "        label = label.to(device)\n",
        "        output = model(input).reshape(-1)\n",
        "        loss = criterion(output, label.float())\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        predicted_labels = (torch.sigmoid(output) >= 0.5).float()\n",
        "        train_correct += (predicted_labels == label).sum().item()\n",
        "        train_total += len(label)\n",
        "        pbar.set_postfix(MSE=loss.item())\n",
        "        train_loss += loss\n",
        "  train_loss /= len(train_loader.dataset)\n",
        "  scheduler.step(train_loss)\n",
        "  train_acc = train_correct / train_total\n",
        "  print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")  \n",
        "\n",
        "  test_loss = 0.0\n",
        "  test_correct = 0\n",
        "  test_total = 0\n",
        "  pbar = tqdm(test_loader)\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "      for i, data in enumerate(pbar, 0):\n",
        "          input, label, groupings = cur_train\n",
        "          input = tuple(map(tokenize, input))\n",
        "          input = torch.Tensor(input).long().to(device)\n",
        "          label = label.to(device)\n",
        "          output = model(input).reshape(-1)\n",
        "          loss = criterion(output, label.float())\n",
        "          predicted_labels = (torch.sigmoid(output) >= 0.5).float()\n",
        "          test_total += len(label)\n",
        "          test_correct += (predicted_labels == label).sum().item()\n",
        "          test_loss += loss\n",
        "          pbar.set_postfix(MSE=loss.item())\n",
        "      \n",
        "  test_loss /= len(test_loader.dataset)\n",
        "  test_acc = test_correct / test_total\n",
        "  print(f\"Epoch {epoch+1}/{num_epochs}, Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}\")\n",
        "\n",
        "\n",
        "from wilds.common.data_loaders import get_eval_loader\n",
        "\n",
        "# Get the test set\n",
        "test_data = dataset.get_subset(\n",
        "    \"test\",\n",
        ")\n",
        "\n",
        "# Prepare the data loader\n",
        "test_loader = get_eval_loader(\"standard\", test_data, batch_size=32)\n",
        "trues = []\n",
        "preds = []\n",
        "metadatas = []\n",
        "for input, true, metadata in test_loader:\n",
        "    with torch.no_grad():\n",
        "      input = tuple(map(tokenize, input))\n",
        "      input = torch.Tensor(input).long().to(device)\n",
        "      output = model(input)\n",
        "      output = (torch.sigmoid(output) >= 0.5).long().reshape(-1)\n",
        "      trues.append(true.to('cpu'))\n",
        "      preds.append(output.to('cpu'))\n",
        "      metadatas.append(metadata.to('cpu'))\n",
        "all_preds = torch.cat(preds, dim = 0)\n",
        "all_trues = torch.cat(trues, dim = 0)\n",
        "all_metas = torch.cat(metadatas, dim = 0)\n",
        "print(dataset.eval(all_preds, all_trues, all_metas))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3xMBbwHfya4",
        "outputId": "2fba13f6-68b3-4129-fc85-9a51e9aaaa89"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/8407 [00:00<?, ?it/s]<ipython-input-10-443b30f9368f>:97: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  input = torch.Tensor(input).long().to(device)\n",
            "100%|██████████| 8407/8407 [00:53<00:00, 158.59it/s, MSE=0.828]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20, Train Loss: 0.0181, Train Acc: 0.6767\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 8408/8408 [00:49<00:00, 169.70it/s, MSE=1.06]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20, Test Loss: 0.0331, Test Acc: 0.7812\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 8407/8407 [00:50<00:00, 167.12it/s, MSE=0.673]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/20, Train Loss: 0.0179, Train Acc: 0.6824\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 8408/8408 [00:42<00:00, 197.05it/s, MSE=0.642]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/20, Test Loss: 0.0201, Test Acc: 0.9688\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 8407/8407 [00:50<00:00, 167.68it/s, MSE=0.97]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/20, Train Loss: 0.0185, Train Acc: 0.6713\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 8408/8408 [00:45<00:00, 183.59it/s, MSE=1.85]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/20, Test Loss: 0.0577, Test Acc: 0.8125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8407/8407 [00:49<00:00, 170.01it/s, MSE=0.732]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/20, Train Loss: 0.0179, Train Acc: 0.6838\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8408/8408 [00:43<00:00, 194.37it/s, MSE=0.701]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/20, Test Loss: 0.0219, Test Acc: 0.9062\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8407/8407 [00:49<00:00, 171.55it/s, MSE=1.19]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/20, Train Loss: 0.0180, Train Acc: 0.6679\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8408/8408 [00:43<00:00, 194.44it/s, MSE=1.28]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/20, Test Loss: 0.0399, Test Acc: 0.9375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8407/8407 [00:50<00:00, 165.07it/s, MSE=1.09]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/20, Train Loss: 0.0183, Train Acc: 0.6749\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8408/8408 [00:48<00:00, 173.69it/s, MSE=1.49]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/20, Test Loss: 0.0465, Test Acc: 0.8750\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8407/8407 [00:51<00:00, 163.12it/s, MSE=1.17]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/20, Train Loss: 0.0179, Train Acc: 0.6787\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8408/8408 [00:44<00:00, 186.87it/s, MSE=1.07]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/20, Test Loss: 0.0334, Test Acc: 0.2812\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8407/8407 [00:52<00:00, 160.65it/s, MSE=0.816]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/20, Train Loss: 0.0184, Train Acc: 0.6804\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8408/8408 [00:47<00:00, 177.94it/s, MSE=1.05]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/20, Test Loss: 0.0328, Test Acc: 0.8750\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8407/8407 [00:50<00:00, 165.21it/s, MSE=1.44]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/20, Train Loss: 0.0179, Train Acc: 0.6863\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8408/8408 [00:43<00:00, 191.17it/s, MSE=1.26]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/20, Test Loss: 0.0395, Test Acc: 0.9062\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8407/8407 [00:52<00:00, 160.54it/s, MSE=0.839]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/20, Train Loss: 0.0156, Train Acc: 0.7593\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8408/8408 [00:49<00:00, 170.06it/s, MSE=2]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/20, Test Loss: 0.0625, Test Acc: 0.6875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8407/8407 [00:51<00:00, 163.13it/s, MSE=1.05]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/20, Train Loss: 0.0170, Train Acc: 0.7128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8408/8408 [00:45<00:00, 186.26it/s, MSE=0.997]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/20, Test Loss: 0.0311, Test Acc: 0.8750\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8407/8407 [00:52<00:00, 160.98it/s, MSE=1.18]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/20, Train Loss: 0.0178, Train Acc: 0.6887\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8408/8408 [00:47<00:00, 178.00it/s, MSE=1.61]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/20, Test Loss: 0.0502, Test Acc: 0.3438\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8407/8407 [00:52<00:00, 161.48it/s, MSE=1.21]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/20, Train Loss: 0.0187, Train Acc: 0.6806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8408/8408 [00:44<00:00, 189.35it/s, MSE=1.02]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/20, Test Loss: 0.0319, Test Acc: 0.8125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8407/8407 [00:53<00:00, 155.99it/s, MSE=0.392]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/20, Train Loss: 0.0177, Train Acc: 0.6823\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8408/8408 [00:45<00:00, 185.25it/s, MSE=0.409]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/20, Test Loss: 0.0128, Test Acc: 0.8125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8407/8407 [00:51<00:00, 163.44it/s, MSE=0.332]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/20, Train Loss: 0.0176, Train Acc: 0.6922\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8408/8408 [00:44<00:00, 189.22it/s, MSE=0.275]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/20, Test Loss: 0.0086, Test Acc: 0.9062\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8407/8407 [00:49<00:00, 168.97it/s, MSE=0.855]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/20, Train Loss: 0.0182, Train Acc: 0.6751\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8408/8408 [00:49<00:00, 171.59it/s, MSE=2.53]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/20, Test Loss: 0.0792, Test Acc: 0.8125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8407/8407 [00:49<00:00, 170.79it/s, MSE=0.742]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/20, Train Loss: 0.0183, Train Acc: 0.6736\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8408/8408 [00:43<00:00, 193.70it/s, MSE=0.73]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/20, Test Loss: 0.0228, Test Acc: 0.9688\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8407/8407 [00:49<00:00, 168.80it/s, MSE=1.15]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18/20, Train Loss: 0.0184, Train Acc: 0.6748\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8408/8408 [00:52<00:00, 160.46it/s, MSE=0.75]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18/20, Test Loss: 0.0234, Test Acc: 0.8125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8407/8407 [00:50<00:00, 166.57it/s, MSE=0.681]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19/20, Train Loss: 0.0190, Train Acc: 0.6676\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8408/8408 [00:46<00:00, 179.00it/s, MSE=2.31]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19/20, Test Loss: 0.0723, Test Acc: 0.7812\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8407/8407 [00:51<00:00, 164.24it/s, MSE=0.836]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20/20, Train Loss: 0.0188, Train Acc: 0.6688\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8408/8408 [00:46<00:00, 181.49it/s, MSE=0.528]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20/20, Test Loss: 0.0165, Test Acc: 0.6562\n",
            "({'acc_avg': 0.6861236691474915, 'acc_y:0_male:1': 0.7440456748008728, 'count_y:0_male:1': 12092.0, 'acc_y:1_male:1': 0.24194280803203583, 'count_y:1_male:1': 2203.0, 'acc_y:0_female:1': 0.7530150413513184, 'count_y:0_female:1': 14179.0, 'acc_y:1_female:1': 0.23127754032611847, 'count_y:1_female:1': 2270.0, 'acc_y:0_LGBTQ:1': 0.7489096522331238, 'count_y:0_LGBTQ:1': 3210.0, 'acc_y:1_LGBTQ:1': 0.2565789520740509, 'count_y:1_LGBTQ:1': 1216.0, 'acc_y:0_christian:1': 0.7276257872581482, 'count_y:0_christian:1': 12101.0, 'acc_y:1_christian:1': 0.27222222089767456, 'count_y:1_christian:1': 1260.0, 'acc_y:0_muslim:1': 0.7521942257881165, 'count_y:0_muslim:1': 5355.0, 'acc_y:1_muslim:1': 0.258143812417984, 'count_y:1_muslim:1': 1627.0, 'acc_y:0_other_religions:1': 0.7442952990531921, 'count_y:0_other_religions:1': 2980.0, 'acc_y:1_other_religions:1': 0.26730769872665405, 'count_y:1_other_religions:1': 520.0, 'acc_y:0_black:1': 0.7526236772537231, 'count_y:0_black:1': 3335.0, 'acc_y:1_black:1': 0.2563435137271881, 'count_y:1_black:1': 1537.0, 'acc_y:0_white:1': 0.7288135886192322, 'count_y:0_white:1': 5723.0, 'acc_y:1_white:1': 0.24621549248695374, 'count_y:1_white:1': 2246.0, 'acc_wg': 0.23127754032611847}, 'Average acc: 0.686\\n  male                   acc on non_toxic: 0.744 (n =  12092)    acc on toxic: 0.242 (n =   2203) \\n  female                 acc on non_toxic: 0.753 (n =  14179)    acc on toxic: 0.231 (n =   2270) \\n  LGBTQ                  acc on non_toxic: 0.749 (n =   3210)    acc on toxic: 0.257 (n =   1216) \\n  christian              acc on non_toxic: 0.728 (n =  12101)    acc on toxic: 0.272 (n =   1260) \\n  muslim                 acc on non_toxic: 0.752 (n =   5355)    acc on toxic: 0.258 (n =   1627) \\n  other_religions        acc on non_toxic: 0.744 (n =   2980)    acc on toxic: 0.267 (n =    520) \\n  black                  acc on non_toxic: 0.753 (n =   3335)    acc on toxic: 0.256 (n =   1537) \\n  white                  acc on non_toxic: 0.729 (n =   5723)    acc on toxic: 0.246 (n =   2246) \\nWorst-group acc: 0.231\\n')\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}